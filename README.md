Ğ’Ğ¾Ñ‚ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ â€œĞºÑ€Ğ°ÑĞ¸Ğ²Ğ¾Ğ³Ğ¾â€ README, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑÑ€Ğ°Ğ·Ñƒ Ñ€Ğ°Ğ·Ğ¼ĞµÑÑ‚Ğ¸Ñ‚ÑŒ Ğ½Ğ° GitHub. ĞĞ½ ĞºĞ¾Ğ¼Ğ¿Ğ°ĞºÑ‚Ğ½Ñ‹Ğ¹, Ñ Ğ±ĞµĞ¹Ğ´Ğ¶Ğ°Ğ¼Ğ¸ Ğ¸ Ğ²Ğ¸Ğ·ÑƒĞ°Ğ»ÑŒĞ½Ğ¾Ğ¹ ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¾Ğ¹:

---

# ğŸš€ Transfer Learning with MobileNetV2 on CIFAR Dataset

[![Python](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

This repository demonstrates **transfer learning** using **MobileNetV2** for classification on selected classes from **CIFAR-10**. Supports **Freeze**, **Partial**, and **Full** fine-tuning modes.

---

## ğŸ“‚ Project Structure

```
transfer_curs/
â”‚
â”œâ”€â”€ configs/          # YAML configs for training modes
â”œâ”€â”€ data/             # CIFAR-10 dataset folder
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/       # Model loading & freezing utilities
â”‚   â””â”€â”€ training/     # Training scripts & Trainer class
â”œâ”€â”€ utils/            # Config loader, seed setting, helpers
â”œâ”€â”€ outputs/          # Saved plots & checkpoints
â”œâ”€â”€ test.py           # Test model and trainable parameters
â””â”€â”€ main_train.py     # Full training with visualization
```

---

## âš™ï¸ Installation

```bash
git clone https://github.com/<your-username>/transfer_curs.git
cd transfer_curs
conda create -n finetune python=3.11
conda activate finetune
pip install torch torchvision matplotlib seaborn pyyaml
```

---

## ğŸ“ Configuration

Control training via YAML files in `configs/`:

| Config         | Mode              | Description                  |
| -------------- | ----------------- | ---------------------------- |
| `freeze.yaml`  | Freeze all layers | Only classifier is trainable |
| `partial.yaml` | Partial unfreeze  | Last N layers trainable      |
| `full.yaml`    | Full fine-tune    | Entire model trainable       |

**Example (`freeze.yaml`):**

```yaml
inherits: "base.yaml"
training:
  mode: "freeze"
  lr: 1e-3
```

---

## ğŸƒ Usage

### 1. Test the model

```bash
python test.py --config configs/freeze.yaml
```

* Prints total & trainable parameters for each mode.
* Verifies forward pass.

### 2. Train the model

```bash
python main_train.py
```

* Trains **Freeze**, **Partial**, **Full** modes.
* Saves **loss** and **accuracy curves** in `outputs/plots/`.

---

## ğŸ“Š Results

Example after 10 epochs on 3 classes:

| Mode    | Val Accuracy |
| ------- | ------------ |
| Freeze  | 69%          |
| Partial | 73%          |
| Full    | 87%          |

**Plots:**

* `outputs/plots/loss_curves.png` â€“ training & validation loss
* `outputs/plots/accuracy_curves.png` â€“ training & validation accuracy

![Loss Curves](outputs/plots/loss_curves.png)
![Accuracy Curves](outputs/plots/accuracy_curves.png)

---

## ğŸ“š Dataset

Default: **CIFAR-10**

Select classes in config:

```yaml
data:
  type: "cifar10"
  classes: [0, 1, 2]  # Example subset
  batch_size: 32
  image_size: 32
```

> âš ï¸ Number of classes must match dataset labels.

---

## ğŸ“„ License

MIT License

---
