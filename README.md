–í–æ—Ç –≤–∞—Ä–∏–∞–Ω—Ç ‚Äú–∫—Ä–∞—Å–∏–≤–æ–≥–æ‚Äù README, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É —Ä–∞–∑–º–µ—Å—Ç–∏—Ç—å –Ω–∞ GitHub. –û–Ω –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, —Å –±–µ–π–¥–∂–∞–º–∏ –∏ –≤–∏–∑—É–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π:

---

# üöÄ Transfer Learning with MobileNetV2 on CIFAR Dataset

[![Python](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

This repository demonstrates **transfer learning** using **MobileNetV2** for classification on selected classes from **CIFAR-10**. Supports **Freeze**, **Partial**, and **Full** fine-tuning modes.

---

## üìÇ Project Structure

```
transfer_curs/
‚îÇ
‚îú‚îÄ‚îÄ configs/          # YAML configs for training modes
‚îú‚îÄ‚îÄ data/             # CIFAR-10 dataset folder
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ models/       # Model loading & freezing utilities
‚îÇ   ‚îî‚îÄ‚îÄ training/     # Training scripts & Trainer class
‚îú‚îÄ‚îÄ utils/            # Config loader, seed setting, helpers
‚îú‚îÄ‚îÄ outputs/          # Saved plots & checkpoints
‚îú‚îÄ‚îÄ test.py           # Test model and trainable parameters
‚îî‚îÄ‚îÄ main_train.py     # Full training with visualization
```

---

## ‚öôÔ∏è Installation

```bash
git clone https://github.com/<your-username>/transfer_curs.git
cd transfer_curs
conda create -n finetune python=3.11
conda activate finetune
pip install torch torchvision matplotlib seaborn pyyaml
```

---

## üìù Configuration

Control training via YAML files in `configs/`:

| Config         | Mode              | Description                  |
| -------------- | ----------------- | ---------------------------- |
| `freeze.yaml`  | Freeze all layers | Only classifier is trainable |
| `partial.yaml` | Partial unfreeze  | Last N layers trainable      |
| `full.yaml`    | Full fine-tune    | Entire model trainable       |

**Example (`freeze.yaml`):**

```yaml
inherits: "base.yaml"
training:
  mode: "freeze"
  lr: 1e-3
```

---

## üèÉ Usage

### 1. Test the model

```bash
python test.py --config configs/freeze.yaml
```

* Prints total & trainable parameters for each mode.
* Verifies forward pass.

### 2. Train the model

```bash
python main_train.py
```

* Trains **Freeze**, **Partial**, **Full** modes.
* Saves **loss** and **accuracy curves** in `outputs/plots/`.

---

## üìä Results

Example after 10 epochs on 3 classes:

| Mode    | Val Accuracy |
| ------- | ------------ |
| Freeze  | 69%          |
| Partial | 73%          |
| Full    | 87%          |

**Plots:**

* `outputs/plots/loss_curves.png` ‚Äì training & validation loss
* `outputs/plots/accuracy_curves.png` ‚Äì training & validation accuracy

![Loss Curves](outputs/plots/loss_curves.png)
![Accuracy Curves](outputs/plots/accuracy_curves.png)

---

## üìö Dataset

Default: **CIFAR-10**

Select classes in config:

```yaml
data:
  type: "cifar10"
  classes: [0, 1, 2]  # Example subset
  batch_size: 32
  image_size: 32
```

> ‚ö†Ô∏è Number of classes must match dataset labels.

---

## üìÑ License

MIT License

---

–ï—Å–ª–∏ —Ö–æ—á–µ—à—å, —è –º–æ–≥—É —Å–¥–µ–ª–∞—Ç—å –µ—â—ë **–µ—â—ë –±–æ–ª–µ–µ –≥–ª—è–Ω—Ü–µ–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —Å —ç–º–æ–¥–∑–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞ –∏ —Å—Å—ã–ª–∫–∞–º–∏ –Ω–∞ –ø—Ä–∏–º–µ—Ä—ã –≥—Ä–∞—Ñ–∏–∫–æ–≤**, —á—Ç–æ–±—ã README –≤—ã–≥–ª—è–¥–µ–ª –∫–∞–∫ –ø–æ–ª–Ω–æ—Ü–µ–Ω–Ω—ã–π –ø—Ä–æ–µ–∫—Ç –Ω–∞ GitHub, –ø—Ä—è–º–æ –∫–∞–∫ –ø–æ—Ä—Ç—Ñ–æ–ª–∏–æ.

–•–æ—á–µ—à—å, —á—Ç–æ–±—ã —è —Ç–∞–∫ —Å–¥–µ–ª–∞–ª?
